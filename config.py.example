OLLAMA_API_BASE_URL = "http://localhost:11434"
OLLAMA_MODELS_TO_COMPARE = ["llama2", "gemma"] # 例如: ["llama2", "mistral"]

# 將您的 API 金鑰替換為實際值，如果沒有則留空字串
OPENAI_API_KEY = "your_openai_api_key_here"
GOOGLE_API_KEY = "your_google_api_key_here"
DEEPSEEK_API_KEY = "your_deepseek_api_key_here"
OPENROUTER_API_KEY = "your_openrouter_api_key_here"  # 新增 OpenRouter API 金鑰
REPLICATE_API_KEY = "your_replicate_api_key_here"  # 新增 Replicate API 金鑰

# 配置審閱者模型
# 範例: {"openai": "gpt-4o-mini", "gemini": "gemini-1.5-flash-latest", "deepseek": "deepseek-chat", "openrouter": "mistralai/mistral-7b-instruct", "replicate": "owner/model_name:version"}
REVIEWER_MODELS = {
    "openai": None,  # 例如: "gpt-4o-mini"
    "gemini": None,  # 例如: "gemini-1.5-flash-latest"
    "deepseek": None,  # 例如: "deepseek-chat"
    "openrouter": None, # 例如: "mistralai/mistral-7b-instruct" 或 "xai-research/grok-1"
    "replicate": None, # 例如: "meta/meta-llama-3-70b-instruct:096394a330869f80fc22939960bb01f805051b6558178033ab8403439211786e"
}

# 配置各評審模型的 temperature 參數
# 某些模型（如 O3/O4 系列）不允許用戶指定 temperature 參數
# 如果模型不支援自定義 temperature，請設為 1，系統會跳過此參數
# 設為 None 或其他值時，會正常傳入該 temperature 值
REVIEWER_TEMPERATURE = {
    "openai": 0.1,      # 一般 OpenAI 模型可調整
    "gemini": 0.1,      # Google Gemini 模型可調整
    "deepseek": 0.1,    # DeepSeek 模型可調整
    "openrouter": 0.1,  # OpenRouter 模型可調整
    "replicate": 0.1,   # Replicate 模型可調整
    # 對於不允許指定 temperature 的模型（如 O3/O4），請設為 1：
    # "openai": 1,      # 不傳入 temperature 參數，使用模型預設值
}

# 支援的任務及其提示詞
SUPPORTED_TASKS = {
    "summarize": "summarize the following text:",
    "translate": "translate the following text to English:",
    # 您可以在此處新增更多任務
}
